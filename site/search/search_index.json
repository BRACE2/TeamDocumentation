{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bridges Name CESMD Repo Hwy8/Meloland Overpass CE01336 Github Painter Street CE89324 Github Lake Crowley CE54730 Github San Bernardino CE23631 Github Tools The following tools are being developed as part of the BRACE2 project. QuakeIO A library of utilities for parsing ground motion files. MotionAPI Ground motion management system. PyG3 High-level threadsafe bindings to the OpenSees framework. Each tool has been designed to closely follow best practices for their respective technology stacks, and extensive documentation for both their design and use is being developed in order to support a maintainable code base. All tools maintain an associated set of validation and verification tests which are integrated into a continuous integration workflow. Various badges are displayed on each tool page to indicate the status and health of the code base. For example, the following badge: on the QuakeIO tool page indicates whether or not the test suite is currently passing. strongmotioncenter.org/stationmap_worldwide/all_stations.php","title":""},{"location":"bridges/","text":"var HelloMessage = React.createClass({ render: function() { return <table>Hello {this.props.name}</table>; } }); ReactDOM.render(<HelloMessage name=\"John\" />, document.getElementById('app')); function bridge_links(csmipid) return { csmip_motions: 'https://www.strongmotioncenter.org/cgi-bin/CESMD/' +'Multiplesearch1_DM2.pl?event_name=&magmin=&magmax=' +'&byear=&eyear=&country=Any&state=Any&stn_ident=&network=CE' +'&sta_number=23631' +'&type=Any&Material=Any&Height=&siteclass=Any&accmin=&accmax=&hdistmin=&hdistmax=', csmip_summary: '' } var data = ` meloland: cesmd: CE01336 calid: 58-0215 general: Year built: ~ Location: \"32.7735 N, 115.4481 W\" Bridge name: \"Hwy8/Meloland Overpass\" structure: Plan shape: straight with skew crowley: cesmd: CE54730 calid: 47-0048 general: Year built: # 1969 ? structure: Plan shape: straight with skew accelerometers: Year fitted: 1977 Bridge count: 17 Free-field count: 3 painter: cesmd: CE89324 # also CE89462 calid: 04-0236 general: Year built: 1976 Location: \"40.5031 N, 124.1009 W\" Bridge Name: ~ structure: Plan shape: straight with skew Foundation Type: Concrete piles. Substructure Type: Circular concrete columns. 2 columns per bent. Superstructure Type: Continuous concrete box girder. Diaphragm abutments. accelerometers: Year fitted: 1977 Bridge count: 17 Free-field count: 3 bernardino: cesmd: CE23631 calid: 54-823G general: Year built: 1969 Location: \"37.5733 N, 1187390 W\" Bridge Name: \"San Bernardino - I10/215 Interchange\" hayward: ~ cesmd: CE58658 calid: 33-0214L general: Year built: 1988 Location: \"37.6907 N, 122.0993 W\" Bridge name: \"Route 580/238 Separation\" structure: Plan shape: curved accelerometers: ground_channels: [ 1, 2, 3, 6, 7, 17, 18, 24, 25] bridge_channels: [11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23] `","title":""},{"location":"bridges/bernard/models/","text":"San Bernardino","title":"San Bernardino\n"},{"location":"bridges/crowley/model/","text":"Crowley","title":"Crowley\n"},{"location":"bridges/hayward/model/","text":"Hayward","title":"Hayward Bridge"},{"location":"bridges/meloland/model/","text":"Meloland","title":"Meloland"},{"location":"bridges/painter/events/","text":"Events","title":"Events\n"},{"location":"bridges/painter/models/","text":"Models","title":"Models\n"},{"location":"notes/","text":"Notes 1","title":"Notes\n"},{"location":"notes/1/","text":"Memo 1: Web Security Concerns for the First MotionAPI Beta-Release This memo collects various resources concerning web security, and lays a foundation for the security of the MotionAPI developed for the BRACE2 project. The MotionAPI currently uses JWT authentication tokens that are created in-house and tightly controlled. The following resources may be useful for further assessing the security of the MotionAPI and other web services which may be incorporated into the BRACE2 project. OWASP Application Security Verification Standard NIST Guide to Secure Web Services Best practices 4 Most Used REST API Authentication Methods Choosing an Authentication Method Why and when to use API keys","title":"Memo 1: Web Security Concerns for the First MotionAPI Beta-Release\n"},{"location":"notes/2/","text":"Framework Overview","title":"Framework Overview\n"},{"location":"notes/3/","text":"Survey of Methods for System Identification Single Input-Single Output (SISO) discrete filter modeling is covered first, subsequently, Multiple Input-Single Output (MISO) discrete time filters are presented. Transfer function modeling [ @yalin2006 ;] State-Space formulations, OKID-ERA-DC, etc [@yalin2006] System Realization by Information Matrix (SRIM) Observer Kalman Filter Identification-Eigen Realization Algorithm with Direct Correlations (OKID-ERA-DC), Detailed coverage of OKID-ERA can be found in Juang (1994) Smyth, 2000: SI using strong motion vs low amplitude forced vibration Transfer Function Modeling Non-Parametric Identification (Bendat and Piersol, 1993) and (Ljung, 1997).","title":"Survey of Methods for System Identification\n"},{"location":"schemas/","text":"Modeling Schemas RandomVariable StructuralModel Ground Motion / Event Schemas QuakeSeries is an array-like data type which contains a single time series, and associated metadata like peak values and units. All data contained by this type is generally closely related to a single physical quantity or measurement . An example of a file format which parses to this type is the PEER NGA .AT2 file. QuakeComponent is a collection of QuakeSeries types which generally represents time series data (e.g. acceleration, velocity, displacement) which were collected in a single direction . An example of a file format that parses into this type is the CSMIP Volume 2 ( .V2 ) spec. QuakeMotion is a collection of QuakeComponent types which all pertain to a single shared spacial location . The data contained by this type is generally free of any spacial variation. QuakeCollection is a collection of QuakeMotion types, often corresponding to a single site . An example of a file format that parses into this type is the CSMIP processed archive ( .zip ).","title":""},{"location":"schemas/elasticmaterial/","text":"ElasticMaterial Schema undefined Elastic uniaxial material. Abstract Extensible Status Identifiable Custom Properties Additional Properties Access Restrictions Defined In Can be instantiated No Unknown status No Forbidden Allowed none ElasticMaterial.schema.json ElasticMaterial Type object ( ElasticMaterial ) ElasticMaterial Default Value The default value is: {} ElasticMaterial Examples { \"name\" : \"1\" , \"type\" : \"ElasticMaterial\" , \"Epos\" : 439679 , \"Eneg\" : 439679 , \"eta\" : 0 } ElasticMaterial Properties Property Type Required Nullable Defined by name string Required cannot be null ElasticMaterial type string Required cannot be null ElasticMaterial Epos integer Required cannot be null ElasticMaterial Eneg number Required cannot be null ElasticMaterial eta number Required cannot be null ElasticMaterial Additional Properties Any Optional can be null name name is required Type: string ( The name schema ) cannot be null defined in: ElasticMaterial name Type string ( The name schema ) type type is required Type: string ( The type schema ) cannot be null defined in: ElasticMaterial type Type string ( The type schema ) Epos An explanation about the purpose of this instance. Epos is required Type: integer ( The Epos schema ) cannot be null defined in: ElasticMaterial Epos Type integer ( The Epos schema ) Epos Examples 439679 Eneg An explanation about the purpose of this instance. Eneg is required Type: number ( The Eneg schema ) cannot be null defined in: ElasticMaterial Eneg Type number ( The Eneg schema ) Eneg Examples 439679 eta An explanation about the purpose of this instance. eta is required Type: number ( The eta schema ) cannot be null defined in: ElasticMaterial eta Type number ( The eta schema ) eta Examples 0 Additional Properties Additional properties are allowed and do not have to follow a specific schema","title":"ElasticMaterial Schema\n"},{"location":"schemas/quakecollection/","text":"QuakeCollection Properties Property Type Required Nullable Defined by motions array Required cannot be null QuakeCollection Additional Properties Any Optional can be null motions motions is required Type: object[] ( QuakeMotion ) cannot be null defined in: QuakeCollection motions Type object[] ( QuakeMotion ) Additional Properties Additional properties are allowed and do not have to follow a specific schema","title":"QuakeCollection Properties\n"},{"location":"schemas/quakecomponent/","text":"QuakeComponent Properties Property Type Required Nullable Defined by accel object Optional cannot be null QuakeComponent veloc object Optional cannot be null QuakeComponent displ object Optional cannot be null QuakeComponent ihdr array Optional cannot be null QuakeComponent rhdr array Optional cannot be null QuakeComponent location string Optional cannot be null QuakeComponent station_no string Optional cannot be null QuakeComponent azimuth string Optional cannot be null QuakeComponent instr_period number Optional cannot be null QuakeComponent instr_period.units string Optional cannot be null QuakeComponent peak_accel number Required cannot be null QuakeComponent peak_accel.units string Required cannot be null QuakeComponent accel.time_step number Optional cannot be null QuakeComponent peak_accel.time number Required cannot be null QuakeComponent peak_veloc number Required cannot be null QuakeComponent peak_veloc.units string Required cannot be null QuakeComponent peak_veloc.time number Required cannot be null QuakeComponent peak_displ number Required cannot be null QuakeComponent peak_displ.units string Required cannot be null QuakeComponent peak_displ.time number Required cannot be null QuakeComponent init_displ number Optional cannot be null QuakeComponent init_displ.units string Optional cannot be null QuakeComponent init_veloc number Optional cannot be null QuakeComponent init_veloc.units string Optional cannot be null QuakeComponent file_name string Optional cannot be null QuakeComponent Additional Properties Any Optional can be null accel accel is optional Type: object ( QuakeSeries ) cannot be null defined in: QuakeComponent accel Type object ( QuakeSeries ) veloc veloc is optional Type: object ( QuakeSeries ) cannot be null defined in: QuakeComponent veloc Type object ( QuakeSeries ) displ displ is optional Type: object ( QuakeSeries ) cannot be null defined in: QuakeComponent displ Type object ( QuakeSeries ) ihdr Integer header data ihdr is optional Type: integer[] cannot be null defined in: QuakeComponent ihdr Type integer[] rhdr rhdr is optional Type: number[] cannot be null defined in: QuakeComponent rhdr Type number[] location Number identifying station at which the data was recorded. location is optional Type: string ( Location ) cannot be null defined in: QuakeComponent location Type string ( Location ) station_no Number identifying station at which the data was recorded. station_no is optional Type: string ( Station number ) cannot be null defined in: QuakeComponent station_no Type string ( Station number ) azimuth azimuth is optional Type: string ( Azimuth ) cannot be null defined in: QuakeComponent azimuth Type string ( Azimuth ) azimuth Examples \"37.691N, 122.099W\" instr_period instr_period is optional Type: number ( Instrument period ) cannot be null defined in: QuakeComponent instr_period Type number ( Instrument period ) instr_period Examples 0.0047 instr_period.units instr_period.units is optional Type: string ( Instrument period units ) cannot be null defined in: QuakeComponent instr_period.units Type string ( Instrument period units ) instr_period.units Examples \"sec\" peak_accel peak_accel is required Type: number ( Peak acceleration ) cannot be null defined in: QuakeComponent peak_accel Type number ( Peak acceleration ) peak_accel Examples 17.433 peak_accel.units peak_accel.units is required Type: string ( Peak acceleration units ) cannot be null defined in: QuakeComponent peak_accel.units Type string ( Peak acceleration units ) peak_accel.units Examples \"cm/sec/sec\" accel.time_step accel.time_step is optional Type: number ( Time step of acceleration data ) cannot be null defined in: QuakeComponent accel.time_step Type number ( Time step of acceleration data ) peak_accel.time peak_accel.time is required Type: number ( Time of peak acceleration ) cannot be null defined in: QuakeComponent peak_accel.time Type number ( Time of peak acceleration ) peak_accel.time Examples 20.27 peak_veloc peak_veloc is required Type: number ( Peak velocity ) cannot be null defined in: QuakeComponent peak_veloc Type number ( Peak velocity ) peak_veloc Examples 0.205 peak_veloc.units peak_veloc.units is required Type: string ( peak_veloc.units ) cannot be null defined in: QuakeComponent peak_veloc.units Type string ( peak_veloc.units ) peak_veloc.units Examples \"cm/sec\" peak_veloc.time peak_veloc.time is required Type: number ( Time of peak velocity ) cannot be null defined in: QuakeComponent peak_veloc.time Type number ( Time of peak velocity ) peak_displ peak_displ is required Type: number ( Peak displacement ) cannot be null defined in: QuakeComponent peak_displ Type number ( Peak displacement ) peak_displ.units peak_displ.units is required Type: string ( peak_displ.units ) cannot be null defined in: QuakeComponent peak_displ.units Type string ( peak_displ.units ) peak_displ.units Examples \"cm\" peak_displ.time peak_displ.time is required Type: number ( Time of peak displacement ) cannot be null defined in: QuakeComponent peak_displ.time Type number ( Time of peak displacement ) peak_displ.time Examples 20.27 init_displ init_displ is optional Type: number ( Initial displacement ) cannot be null defined in: QuakeComponent init_displ Type number ( Initial displacement ) init_displ.units Units init_displ.units is optional Type: string ( init_displ.units ) cannot be null defined in: QuakeComponent init_displ.units Type string ( init_displ.units ) init_displ.units Examples \"cm/sec\" init_veloc init_veloc is optional Type: number ( Initial velocity ) cannot be null defined in: QuakeComponent init_veloc Type number ( Initial velocity ) init_veloc.units Initial velocity units init_veloc.units is optional Type: string ( init_veloc.units ) cannot be null defined in: QuakeComponent init_veloc.units Type string ( init_veloc.units ) init_veloc.units Examples \"cm/sec\" file_name file_name is optional Type: string ( Source file name ) cannot be null defined in: QuakeComponent file_name Type string ( Source file name ) Additional Properties Additional properties are allowed and do not have to follow a specific schema","title":"QuakeComponent Properties\n"},{"location":"schemas/quakefilter/","text":"QuakeFilter Properties Property Type Required Nullable Defined by filter_type string Required cannot be null QuakeFilter point number Optional cannot be null QuakeFilter point.units string Optional cannot be null QuakeFilter limit_low number Optional cannot be null QuakeFilter limit_high number Optional cannot be null QuakeFilter limit.units string Optional cannot be null QuakeFilter Additional Properties Any Optional can be null filter_type filter_type is required Type: string ( The filter_type schema ) cannot be null defined in: QuakeFilter filter_type Type string ( The filter_type schema ) point point is optional Type: number ( The point schema ) cannot be null defined in: QuakeFilter point Type number ( The point schema ) point.units point.units is optional Type: string ( The point.units schema ) cannot be null defined in: QuakeFilter point.units Type string ( The point.units schema ) limit_low limit_low is optional Type: number ( The limit_low schema ) cannot be null defined in: QuakeFilter limit_low Type number ( The limit_low schema ) limit_high limit_high is optional Type: number ( The limit_high schema ) cannot be null defined in: QuakeFilter limit_high Type number ( The limit_high schema ) limit.units limit.units is optional Type: string ( The limit.units schema ) cannot be null defined in: QuakeFilter limit.units Type string ( The limit.units schema ) Additional Properties Additional properties are allowed and do not have to follow a specific schema","title":"QuakeFilter Properties\n"},{"location":"schemas/quakemotion/","text":"QuakeMotion Schema #/properties/motions/items#/properties/motions/items Abstract Extensible Status Identifiable Custom Properties Additional Properties Access Restrictions Defined In Can be instantiated No Unknown status No Forbidden Allowed none [QuakeCollection.schema.json*](../../out/QuakeCollection.schema.json \u201copen original schema\u201d) items Type object ( QuakeMotion ) items Properties Property Type Required Nullable Defined by key string Required cannot be null QuakeCollection components array Required cannot be null QuakeCollection Additional Properties Any Optional can be null key key is required Type: string cannot be null defined in: QuakeCollection key Type string components components is required Type: object[] ( QuakeComponent ) cannot be null defined in: QuakeCollection components Type object[] ( QuakeComponent ) Additional Properties Additional properties are allowed and do not have to follow a specific schema","title":"QuakeMotion Schema\n"},{"location":"schemas/quakeseries/","text":"QuakeSeries Properties Property Type Required Nullable Defined by peak_value number Optional cannot be null QuakeSeries units string Required cannot be null QuakeSeries peak_time number Optional cannot be null QuakeSeries shape integer Required cannot be null QuakeSeries time_step number Required cannot be null QuakeSeries data array Optional cannot be null QuakeSeries Additional Properties Any Optional can be null peak_value peak_value is optional Type: number ( Peak value of series data ) cannot be null defined in: QuakeSeries peak_value Type number ( Peak value of series data ) units units is required Type: string ( Series units ) cannot be null defined in: QuakeSeries units Type string ( Series units ) peak_time peak_time is optional Type: number ( Time of peak value ) cannot be null defined in: QuakeSeries peak_time Type number ( Time of peak value ) shape shape is required Type: integer ( Series shape ) cannot be null defined in: QuakeSeries shape Type integer ( Series shape ) time_step time_step is required Type: number ( Time step ) cannot be null defined in: QuakeSeries time_step Type number ( Time step ) data data is optional Type: unknown[] cannot be null defined in: QuakeSeries data Type unknown[] data Default Value The default value is: [] Additional Properties Additional properties are allowed and do not have to follow a specific schema","title":"QuakeSeries Properties\n"},{"location":"schemas/structuralanalysismodel/","text":"The root schema Properties Property Type Required Nullable Defined by StructuralAnalysisModel object Required cannot be null The root schema Additional Properties Any Optional can be null StructuralAnalysisModel An explanation about the purpose of this instance. StructuralAnalysisModel is required Type: object ( The StructuralAnalysisModel schema ) cannot be null defined in: The root schema StructuralAnalysisModel Type object ( The StructuralAnalysisModel schema ) StructuralAnalysisModel Default Value The default value is: {} Additional Properties Additional properties are allowed and do not have to follow a specific schema","title":"The root schema Properties\n"},{"location":"schemas/structuralgeometry/","text":"Model geometry Properties Property Type Required Nullable Defined by nodes array Required cannot be null Model geometry elements array Required cannot be null Model geometry Additional Properties Any Optional can be null nodes Array of structural nodes. nodes is required Type: object[] ( Node ) cannot be null defined in: Model geometry nodes Type object[] ( Node ) nodes Default Value The default value is: [] nodes Examples [ { \"name\" : 0 , \"ndf\" : 6 , \"crd\" : [ 0 , 240.453 , 0 ] , \"mass\" : [ 0 , 0 , 0 , 0 , 0 , 0 ] } ] elements An explanation about the purpose of this instance. elements is required Type: an array of merged types ( Details ) cannot be null defined in: Model geometry elements Type an array of merged types ( Details ) elements Default Value The default value is: [] elements Examples [ { \"name\" : 0 , \"type\" : \"ElasticBeam3d\" , \"nodes\" : [ 0 , 2 ] , \"E\" : 4074000 , \"G\" : 1697500 , \"A\" : 6476 , \"Jx\" : 79505000 , \"Iy\" : 74980000 , \"Iz\" : 4525000 , \"massperlength\" : 1.40742 , \"releasez\" : 0 , \"releasey\" : 0 , \"crdTransformation\" : \"1\" } ] Additional Properties Additional properties are allowed and do not have to follow a specific schema","title":"Model geometry Properties\n"},{"location":"schemas/structuralnode/","text":"Node Schema #/properties/StructuralAnalysisModel/properties/geometry/properties/nodes/items Abstract Extensible Status Identifiable Custom Properties Additional Properties Access Restrictions Defined In Can be instantiated No Unknown status No Forbidden Allowed none StructuralNode.schema.json Node Type object ( Node ) Node Examples { \"name\" : 0 , \"ndf\" : 6 , \"crd\" : [ 0 , 240.453 , 0 ] , \"mass\" : [ 0 , 0 , 0 , 0 , 0 , 0 ] } Node Properties Property Type Required Nullable Defined by name integer Required cannot be null Node ndf integer Required cannot be null Node crd array Required cannot be null Node mass array Optional cannot be null Node Additional Properties Any Optional can be null name An explanation about the purpose of this instance. name is required Type: integer ( Node name ) cannot be null defined in: Node name Type integer ( Node name ) ndf Number of degrees-of-freedom at node. ndf is required Type: integer ( Node degrees of freedom ) cannot be null defined in: Node ndf Type integer ( Node degrees of freedom ) ndf Examples 6 crd Node spatial coordinates. crd is required Type: an array of merged types ( Details ) cannot be null defined in: Node crd Type an array of merged types ( Details ) crd Examples [ 0 , 240.453 ] mass Assigned mass of each DOF at node. mass is optional Type: an array of merged types ( Details ) cannot be null defined in: Node mass Type an array of merged types ( Details ) mass Default Value The default value is: [ [ 0 , 0 , 0 ] ] Additional Properties Additional properties are allowed and do not have to follow a specific schema","title":"Node Schema\n"},{"location":"schemas/structuralresponse/","text":"Untitled object in undefined Properties Property Type Required Nullable Defined by nodal_response object Optional cannot be null Untitled schema element_response Not specified Optional cannot be null Untitled schema nodal_response nodal_response is optional Type: object ( Details ) cannot be null defined in: Untitled schema nodal_response Type object ( Details ) element_response element_response is optional Type: unknown cannot be null defined in: Untitled schema element_response Type unknown","title":"Untitled object in undefined Properties\n"},{"location":"tools/MotionAPI/","text":"Motion API The BRACE2 MotionAPI provides a controlled point of contact for sharing and managing ground motion records in real time. The tool consists of a \u201cbackend\u201d server application, and a \u201cfrontend\u201d web application. The backend provides a REST API which acts as the controlled point of contact, through which all data passes. This endpoint can be programatically accessed in a uniform manner from virtually any programming language (see the documentation for examples in Python, Shell, Go, Rust and more). Examples Design","title":"Motion API\n"},{"location":"tools/MotionAPI/design/","text":"Design THIS PAGE IS UNDER DEVELOPMENT File uploads are send as HTTP POST operations with a MIME type of multipart/form-data ([RFC 2046]). Frontends REST API The REST API is integrated directly into the Django application. React web app The frontend web app is built using ReactJS. Backend The backend application is comprised of the server, REST API, Database, and authentication mechanism. Server This is a Python application that is written using the Django framework. This application listens to a server port for API requests, and fulfills these requests by interacting with the database. Authentication Authentication Database The application database is responsible for storing metadata for earthquake records. This database is built using the SQLite database management system, but nearly all operations are performed in the background by the Django Python library. API api/events/ Return all existing events.","title":"Design\n"},{"location":"tools/MotionAPI/examples/","text":"API Examples This page collects examples which demonstrate interactions with the API from various programming languages. See https//curlconverter.com/ for more. Get all motions Python import sys import json import requests Payload parameters # Framework parameters # ---------------------------------- username, password = [ \"brace2\" ] * 2 host = \"http://localhost:8000\" # Setup API request # ---------------------------------- headers = { \"Content-Type\" : \"Application/JSON\" , } response = requests.get( host + \"/api/events/\" , headers = headers, auth = (username, password) ) # print(json.loads(response.text)) print (response.json()) Shell ( curl ) #!/bin/sh hostname = \"localhost:8000\" username = \"brace2\" password = \"brace2\" event_id = \" $1 \" curl -X GET \\ -H 'Content-Type:Application/JSON' \\ -u $username : $password \\ $hostname /api/events/ printf \"\\n\" Get a single motion C #if 0 EXEC=${0%.*} test -x \"$EXEC\" || clang \"$0\" -lcurl -o \"$EXEC\" exec \"$EXEC\" exit { #endif #include <stdio.h> #include <stdlib.h> #include \"curl/curl.h\" int main ( void ) { int status = EXIT_SUCCESS ; const char * username = \"brace2\" , * password = \"brace2\" , * hostname = \"localhost:8000\" ; char * url = mkstr ( \"https://%s:%s@%s/api/events/\" , username , password , hostname ); CURL * curl ; char buffer [ CURL_ERROR_SIZE ]; if (( curl = curl_easy_init ()) != NULL ) { curl_easy_setopt ( curl , CURLOPT_URL , url ); curl_easy_setopt ( curl , CURLOPT_FOLLOWLOCATION , 1 ); curl_easy_setopt ( curl , CURLOPT_ERRORBUFFER , buffer ); if ( curl_easy_perform ( curl ) != CURLE_OK ) { fprintf ( stderr , \"%s \\n \" , buffer ); return EXIT_FAILURE ; } curl_easy_cleanup ( curl ); } free ( url ); return EXIT_SUCCESS ; } #if 0 } #endif Go // Claudio Perez package main import ( \"fmt\" \"io/ioutil\" \"log\" \"net/http\" ) func main () { hostname := \"localhost:8000\" username := \"brace2\" password := \"brace2\" client := & http . Client {} req , err := http . NewRequest ( \"GET\" , fmt . Sprintf ( \"%s/api/events/\" , hostname ), nil ) if err != nil { log . Fatal ( err )} req . Header . Set ( \"Content-Type\" , \"Application/JSON\" ) req . SetBasicAuth ( username , password ) resp , err := client . Do ( req ) if err != nil { log . Fatal ( err ) } defer resp . Body . Close () bodyText , err := ioutil . ReadAll ( resp . Body ) if err != nil { log . Fatal ( err ) } fmt . Printf ( \"%s \\n \" , bodyText ) } Upload a new motion In the following examples, a string variable named event_file is used to store the name of the ground motion file to be uploaded. Python import sys import json import requests # Payload parameters # ---------------------------------- name = sys.argv[ 1 ] event_file = \"/home/claudio/pkgs/quakeio/dat/58658_007_20210426_10.09.54.P.zip\" # Framework parameters # ---------------------------------- username, password = [ \"brace2\" ] * 2 hostname = \"http://localhost:8000\" # Setup API request # ---------------------------------- headers = { \"Content-Type\" : \"multipart/form-data\" , } files = { \"event_file\" : (event_file, open (event_file, \"rb\" )), \"name\" : ( None , name), } response = requests.post( hostname + \"/api/events/\" , headers = headers, files = files, auth = (username, password) ) print (json.loads(response)) Shell ( curl )","title":"API Examples\n"},{"location":"tools/MotionAPI/schema/","text":"","title":""},{"location":"tools/Scripts/","text":"Scripts/","title":"Scripts/\n"},{"location":"tools/Scripts/render/","text":"OpenSees Rendering Synopsis `render.py [ ] Arpit Nema , Chrystal Chern , and Claudio Perez This script plots the geometry of a structural model given a SAM JSON file. The SAM JSON structure was developed by the NHERI SimCenter. Installation The simplest way to install this script is to run $ python render.py --install from a terminal that has python installed, in a directory containing the render.py file. This will install the following packages: REQUIREMENTS = \"\"\" pyyaml scipy numpy plotly matplotlib \"\"\" Matlab In order to install the Matlab bindings, open Matlab in a directory containing the files render.py and render.m , and run the following command in the Matlab interpreter: render --install Once this process is complete, the command render can be called from Matlab, just as described below for the command line. Usage This script can be used either as a module, or as a command line utility. When invoked from the command line on Windows , {NAME} should be python -m render . For example: python -m render model.json --axes 2 --view elev The script may be invoked with the following options: NAME = \"render.py\" HELP = f\"\"\" usage: { NAME } <sam-file> { NAME } --install { NAME } [options] <sam-file> { NAME } [options] <sam-file> <res-file> Generate a plot of a structural model. Positional Arguments: <sam-file> JSON file defining the structural model. <res-file> JSON or YAML file defining a structural response. Options: -s, --scale <scale> Set displacement scale factor. -d, --disp <node>:<dof>... Apply a unit displacement at node with tag <node> in direction <dof>. -V, --view {{ elev|plan|sect }} Set camera view. -a, --axes [<L><T>]<V> Specify model axes. Only <V> is required --hide <object> Hide <object>; see '--show'. --show <object> Show <object>; accepts any of: {{ origin|frames|frames.displ|nodes|nodes.displ }} -o, --save <out-file> Save plot to <out-file>. -c, --conf --install Install script dependencies. --script {{ sam|res }} -h, --help Print this message and exit. <dof> {{ long | tran | vert | sect | elev | plan }} {{ 0 | 1 | 2 | 3 | 4 | 5 }} <object> {{ origin|frames|frames.displ|nodes|nodes.displ }} \"\"\" EXAMPLES = \"\"\" Examples: Plot the structural model defined in the file `sam.json`: $ {NAME} sam.json Plot displaced structure with unit translation at nodes 5, 3 and 2 in direction 2 at scale of 100: $ {NAME} -d 5:2,3:2,2:2 -s100 --axes 2 sam.json \"\"\" The remainder of this script is broken into the following sections: Data shaping / Misc. Kinematics Plotting Command line processing Defaults The following configuration options are available: Config = lambda : { \"show_objects\" : [ \"frames\" , \"frames.displ\" , \"nodes\" ], \"hide_objects\" : [ \"origin\" ], \"sam_file\" : None , \"res_file\" : None , \"write_file\" : None , \"displ\" : [], \"scale\" : 100.0 , \"orientation\" : [ 0 , 2 , 1 ], \"view\" : \"iso\" , \"plotter\" : \"mpl\" , \"camera\" : { \"view\" : \"iso\" , # iso | plan| elev[ation] | sect[ion] \"projection\" : \"orthographic\" # perspective | orthographic }, \"displacements\" : { \"scale\" : 100 , \"color\" : \"#660505\" }, \"objects\" : { \"origin\" : { \"color\" : \"black\" }, \"frames\" : { \"color\" : \"#000000\" , \"displaced\" : { \"color\" : \"red\" , \"npoints\" : 20 } }, \"nodes\" : { \"default\" : { \"size\" : 2 , \"color\" : \"#000000\" }, \"displaced\" : {}, \"fixed\" : {}, }, }, \"save_options\" : { # Options for when writing to an HTML file. \"html\" : { \"include_plotlyjs\" : True , \"include_mathjax\" : \"cdn\" , \"full_html\" : True } } } def apply_config(conf, opts): for k,v in conf.items(): print (k,v) if isinstance (v, dict ): apply_conf(v, opts[k]) else : opts[k] = v The following Tcl script can be used to create a results file EIG_SCRIPT = \"\"\" for {set m 1} {$m <= 3} {incr m} { puts \"$m:\" foreach n [getNodeTags] { puts \" $n: \\[[join [nodeEigenvector $n $m] {, }]\\]\"; } } \"\"\" import sys, os try : import yaml import numpy as np Array = np.ndarray FLOAT = np.float32 from scipy.linalg import block_diag except : yaml = None Array = list FLOAT = float NDM = 3 # this script currently assumes ndm=3 Data shaping / Misc. The following functions are used for reshaping data and carrying out other miscellaneous operations. class RenderError( Exception ): pass def wireframe(sam: dict ) -> dict : \"\"\" Process OpenSees JSON output and return dict with the form: {<elem tag>: {\"crd\": [<coordinates>], ...}} \"\"\" geom = sam[ \"geometry\" ] coord = np.array([n.pop( \"crd\" ) for n in geom[ \"nodes\" ]],dtype = FLOAT) nodes = {n[ \"name\" ]: { ** n, \"crd\" : coord[i]} for i,n in enumerate (geom[ \"nodes\" ])} trsfm = {t[ \"name\" ]: t for t in sam[ \"properties\" ][ \"crdTransformations\" ]} elems = { e[ \"name\" ]: dict ( ** e, crd = np.array([nodes[n][ \"crd\" ] for n in e[ \"nodes\" ]], dtype = FLOAT), trsfm = trsfm[e[ \"crdTransformation\" ]] if \"crdTransformation\" in e else None ) for e in geom[ \"elements\" ] } return dict (nodes = nodes, elems = elems, coord = coord) def read_model(filename: str ) -> dict : import json with open (filename, \"r\" ) as f: sam = json.load(f) model = wireframe(sam[ \"StructuralAnalysisModel\" ]) if \"RendererConfiguration\" in sam: model[ \"config\" ] = sam[ \"RendererConfiguration\" ] return model Kinematics The following functions implement various kinematic relations for standard frame models. # Helper functions for extracting rotations in planes elev_dofs = lambda u: u[[ 1 , 2 ]] plan_dofs = lambda u: u[[ 3 , 4 ]] def get_dof_num(dof: str , axes: list ): try : return int (dof) except : return { \"long\" : axes[ 0 ], \"vert\" : axes[ 2 ], \"tran\" : axes[ 1 ], \"sect\" : axes[ 0 ] + 3 , \"plan\" : axes[ 2 ] + 3 , \"elev\" : axes[ 1 ] + 3 }[dof] def elastic_curve(x: Array, v: Array, L: float ) -> Array: \"compute points along Euler's elastica\" vi, vj = v xi = x / L # local coordinates N1 = 1. - 3. * xi ** 2 + 2. * xi ** 3 N2 = L * (xi - 2. * xi ** 2 + xi ** 3 ) N3 = 3. * xi ** 2 - 2 * xi ** 3 N4 = L * (xi ** 3 - xi ** 2 ) y = vi * N2 + vj * N4 return y.flatten() def linear_deformations(u,L): \"\"\" Compute local frame deformations assuming small displacements u: 6-vector of displacements in rotated frame L: element length \"\"\" xi, yi, zi, si, ei, pi = range ( 6 ) # Define variables to aid xj, yj, zj, sj, ej, pj = range ( 6 , 12 ) # reading array indices. elev_chord = (u[zj] - u[zi]) / L # Chord rotations plan_chord = (u[yj] - u[yi]) / L return np.array([ [u[xj] - u[xi]], # xi [u[ei] - elev_chord], # vi_elev [u[ej] - elev_chord], # vj_elev [u[pi] - plan_chord], [u[pj] - plan_chord], [u[sj] - u[si]], ],dtype = FLOAT) def rotation(xyz: Array, vert = ( 0 , 0 , - 1 )) -> Array: \"Create a rotation matrix between local e and global E\" dx = xyz[ 1 ] - xyz[ 0 ] L = np.linalg.norm(dx) e1 = dx / L v13 = np.atleast_1d(vert) v2 = - np.cross(e1,v13) e2 = v2 / np.linalg.norm(v2) v3 = np.cross(e1,e2) e3 = v3 / np.linalg.norm(v3) return np.stack([e1,e2,e3]) def displaced_profile( coord: Array, displ: Array, #: Displacements vect = None , #: Element orientation vector glob: bool = True , #: Transform to global coordinates npoints: int = 10 , ) -> Array: n = npoints # (---ndm---) rep = 4 if len (coord[ 0 ]) == 3 else 2 Q = rotation(coord, vect) L = np.linalg.norm(coord[ 1 ] - coord[ 0 ]) v = linear_deformations(block_diag( * [Q] * rep) @ displ, L) Lnew = L + v[ 0 , 0 ] xaxis = np.linspace( 0.0 , Lnew, n) plan_curve = elastic_curve(xaxis, plan_dofs(v), Lnew) elev_curve = elastic_curve(xaxis, elev_dofs(v), Lnew) #dy,dz = Q[1:,1:]@np.linspace(displ[1:3], displ[7:9], n).T dx,dy,dz = Q @ np.linspace(displ[: 3 ], displ[ 6 : 9 ], n).T local_curve = np.stack([xaxis + dx[ 0 ], plan_curve + dy, elev_curve + dz]) if glob: global_curve = Q.T @ local_curve + coord[ 0 ][ None ,:].T return global_curve Plotting VIEWS = { # pre-defined plot views \"plan\" : dict (azim = 0 , elev = 90 ), \"sect\" : dict (azim = 0 , elev = 0 ), \"elev\" : dict (azim =- 90 , elev = 0 ), \"iso\" : dict (azim = 45 , elev = 35 ) } def new_3d_axis(): import matplotlib.pyplot as plt _, ax = plt.subplots( 1 , 1 , subplot_kw = { \"projection\" : \"3d\" }) ax.set_autoscale_on( True ) ax.set_axis_off() return ax def add_origin(ax,scale): xyz = np.zeros(( 3 , 3 )) uvw = np.eye( 3 ) * scale ax.quiver( * xyz, * uvw, arrow_length_ratio = 0.1 , color = \"black\" ) return ax def set_axis_limits(ax): \"Find and set axes limits\" aspect = [ub - lb for lb, ub in ( getattr (ax, f'get_ { a } lim' )() for a in 'xyz' )] aspect = [ max (a, max (aspect) / 8 ) for a in aspect] ax.set_box_aspect(aspect) def plot_skeletal(frame, axes = None ): if axes is None : axes = [ 0 , 2 , 1 ] props = { \"frame\" : { \"color\" : \"grey\" , \"alpha\" : 0.6 }} ax = new_3d_axis() for e in frame[ \"elems\" ].values(): x,y,z = e[ \"crd\" ].T[axes] ax.plot(x,y,z, ** props[ \"frame\" ]) return ax def plot_nodes(frame, displ = None , axes = None , ax = None ): if axes is None : axes = [ 0 , 2 , 1 ] ax = ax or new_3d_axis() displ = displ or {} Zero = np.zeros(NDM) props = { \"color\" : \"black\" , \"marker\" : \"s\" , \"s\" : 2 , \"zorder\" : 2 } coord = frame[ \"coord\" ] for i,n in enumerate (frame[ \"nodes\" ].values()): coord[i,:] += displ.get(n[ \"name\" ],Zero)[: 3 ] x,y,z = coord.T[axes] ax.scatter(x, y, z, ** props) return ax def plot_displ(frame: dict , res: dict , ax = None , axes = None ): props = { \"color\" : \"#660505\" } ax = ax or new_3d_axis() if axes is None : axes = [ 0 , 2 , 1 ] for el in frame[ \"elems\" ].values(): # exclude zero-length elements if \"zero\" not in el[ \"type\" ].lower(): glob_displ = [ u for n in el[ \"nodes\" ] # extract displ from node, default to ndf zeros for u in res.get(n,[ 0.0 ] * frame[ \"nodes\" ][n][ \"ndf\" ]) ] vect = el[ \"trsfm\" ][ \"vecInLocXZPlane\" ] x,y,z = displaced_profile(el[ \"crd\" ], glob_displ, vect = vect)[axes] ax.plot(x,y,z, ** props) return ax class Plotter: def __init__ ( self ,model, opts, axes = None ): self .model = model if axes is None : axes = [ 0 , 2 , 1 ] self .axes = axes self .opts = opts class GnuPlotter(Plotter): def plot_frames( self ): file = sys.stdout print ( \"\"\" set term wxt unset border unset xtics unset ytics unset ztics set view equal xyz splot \"-\" using 1:2:3 with lines \"\"\" , file = file ) coords = self ._get_frames() np.savetxt( file , coords) def _get_frames( self ): axes = self .axes model = self .model props = { \"color\" : \"#808080\" , \"alpha\" : 0.6 } coords = np.zeros(( len (model[ \"elems\" ]) * 3 ,NDM)) coords.fill(np.nan) for i,e in enumerate (model[ \"elems\" ].values()): coords[ 3 * i: 3 * i + 2 ,:] = e[ \"crd\" ][:,axes] return coords class PlotlyPlotter(Plotter): def plot(x,y, ** opts): pass def plot_frames(): pass def _get_displ( self ,res: dict ): frame = self .model axes = self .axes props = { \"color\" : \"red\" } N = 10 coords = np.zeros(( len (frame[ \"elems\" ]) * (N + 1 ),NDM)) coords.fill(np.nan) for i,el in enumerate (frame[ \"elems\" ].values()): # exclude zero-length elements if \"zero\" not in el[ \"type\" ].lower(): glob_displ = [ u for n in el[ \"nodes\" ] # extract displ from node, default to ndf zeros for u in res.get(n,[ 0.0 ] * frame[ \"nodes\" ][n][ \"ndf\" ]) ] vect = el[ \"trsfm\" ][ \"vecInLocXZPlane\" ] coords[(N + 1 ) * i:(N + 1 ) * i + N,:] = displaced_profile(el[ \"crd\" ], glob_displ, vect = vect, npoints = N)[axes].T x,y,z = coords.T return { \"type\" : \"scatter3d\" , \"mode\" : \"lines\" , \"x\" : x, \"y\" : y, \"z\" : z, \"line\" : { \"color\" :props[ \"color\" ]}, \"hoverinfo\" : \"skip\" } def make_hover_data( self , data, ln = None ): if ln is None : items = np.array([d.values for d in data]) keys = data[ 0 ].keys() else : items = np.array([ list (data.values())] * ln) keys = data.keys() return { \"hovertemplate\" : \"<br>\" .join( f\" { k } : % {{ customdata[ { v } ] }} \" for v,k in enumerate (keys)), \"customdata\" : list (items), } def _get_nodes( self ): x,y,z = self .model[ \"coord\" ].T[ self .axes] keys = [ \"tag\" ,] nodes = np.array( list ( self .model[ \"nodes\" ].keys()),dtype = FLOAT)[:, None ] return { \"name\" : \"nodes\" , \"x\" : x, \"y\" : y, \"z\" : z, \"type\" : \"scatter3d\" , \"mode\" : \"markers\" , \"hovertemplate\" : \"<br>\" .join( f\" { k } : % {{ customdata[ { v } ] }} \" for v,k in enumerate (keys)), \"customdata\" : list (nodes), \"marker\" : { \"symbol\" : \"square\" , ** self .opts[ \"objects\" ][ \"nodes\" ][ \"default\" ] } } def _get_frame_labels( self ): coords = self ._frame_coords.reshape( - 1 , 4 , 3 )[:, - 3 ] x,y,z = coords.T keys = [ \"tag\" ,] frames = np.array( list ( self .model[ \"elems\" ].keys()),dtype = FLOAT)[:, None ] return { \"name\" : \"frames\" , \"x\" : x, \"y\" : y, \"z\" : z, \"type\" : \"scatter3d\" , \"mode\" : \"markers\" , \"hovertemplate\" : \"<br>\" .join( f\" { k } : % {{ customdata[ { v } ] }} \" for v,k in enumerate (keys)), \"customdata\" : frames, \"opacity\" : 0 #\"marker\": {\"opacity\": 0.0,\"size\": 0.0, \"line\": {\"width\": 0.0}} } def _get_frames( self ): N = 4 axes = self .axes model = self .model props = { \"color\" : \"#808080\" , \"alpha\" : 0.6 } coords = np.zeros(( len (model[ \"elems\" ]) * N,NDM)) coords.fill(np.nan) for i,e in enumerate (model[ \"elems\" ].values()): coords[N * i:N * i + N - 1 ,:] = np.linspace( * e[ \"crd\" ][:,axes], N - 1 ) self ._frame_coords = coords x,y,z = coords.T return { \"type\" : \"scatter3d\" , \"mode\" : \"lines\" , \"x\" : x, \"y\" : y, \"z\" : z, \"line\" : { \"color\" :props[ \"color\" ]}, \"hoverinfo\" : \"skip\" } def plot_plotly(model, axes = None , displ = None , opts = {}): import plotly.graph_objects as go plt = PlotlyPlotter(model,axes = axes,opts = opts) frames = plt._get_frames() labels = plt._get_frame_labels() nodes = plt._get_nodes() fig = go.Figure( dict ( #go.Scatter3d(**plot_skeletal_plotly(model,axes)), data = [frames, labels, nodes] + ([plt._get_displ(displ)] if displ else []), layout = go.Layout( scene = dict (aspectmode = 'data' , xaxis_visible = False , yaxis_visible = False , zaxis_visible = False , camera = dict ( projection = { \"type\" : opts[ \"camera\" ][ \"projection\" ]} ) ), showlegend = False ) )) return fig Script functions Argument parsing is implemented manually because in the past I have found the standard library module argparse to be slow. def parse_args(argv) -> dict : opts = Config() if os.path.exists( \".render.yaml\" ): with open ( \".render.yaml\" , \"r\" ) as f: presets = yaml.load(f, Loader = yaml.Loader) apply_config(presets,opts) args = iter (argv[ 1 :]) for arg in args: try : if arg == \"--help\" or arg == \"-h\" : print (HELP) sys.exit() elif arg == \"--gnu\" : opts[ \"plotter\" ] = \"gnu\" elif arg == \"--install\" : try : install_me( next (args)) # if no directory is provided, use default except StopIteration : install_me() sys.exit() elif arg[: 2 ] == \"-d\" : node_dof = arg[ 2 :] if len (arg) > 2 else next (args) for nd in node_dof.split( \",\" ): node, dof = nd.split( \":\" ) opts[ \"displ\" ].append(( int (node), get_dof_num(dof, opts[ \"orientation\" ]))) elif arg[: 2 ] == \"-s\" : opts[ \"scale\" ] = float (arg[ 2 :]) if len (arg) > 2 else float ( next (args)) elif arg == \"--scale\" : opts[ \"scale\" ] = float ( next (args)) elif arg == \"--axes\" : vert = int ( next (args)) tran = 2 if vert == 1 else 1 opts[ \"orientation\" ][ 1 :] = [tran, vert] elif arg == \"--show\" : opts[ \"show_objects\" ].extend( next (args).split( \",\" )) elif arg == \"--hide\" : opts[ \"show_objects\" ].pop( next (args)) elif arg[: 2 ] == \"-V\" : opts[ \"view\" ] = arg[ 2 :] if len (arg) > 2 else next (args) elif arg == \"--view\" : opts[ \"view\" ] = next (args) #elif arg[:2] == \"-m\": # opts[\"mode\"] = int(arg[2]) if len(arg) > 2 else int(next(args)) elif arg[: 2 ] == \"-o\" : opts[ \"write_file\" ] = arg[ 2 :] if len (arg) > 2 else next (args) #elif arg == \"--displ-only\": # opts[\"displ_only\"] = True # Final check on options elif arg[ 0 ] == \"-\" : raise RenderError( f\"ERROR - unknown option ' { arg } '\" ) elif not opts[ \"sam_file\" ]: opts[ \"sam_file\" ] = arg else : opts[ \"res_file\" ] = arg except StopIteration : # `next(args)` was called without successive arg raise RenderError( f\"ERROR -- Argument ' { arg } ' expected value\" ) return opts def install_me(install_opt = None ): import os import subprocess if install_opt == \"dependencies\" : subprocess.check_call([sys.executable, '-m' , 'pip' , 'install' , * REQUIREMENTS.strip().split( \" \\n \" )]) sys.exit() try : from setuptools import setup except ImportError : from distutils.core import setup sys.argv = sys.argv[: 1 ] + [ \"develop\" , \"--user\" ] print (sys.argv) setup(name = 'render' , version = '0.0.1' , description = '' , long_description = HELP, author = '' , author_email = '' , url = '' , py_modules = [ 'render' ], scripts = [ 'render.py' ], license = '' , install_requires = [ * REQUIREMENTS.strip().split( \" \\n \" )], ) TESTS = [ ( False , \" {NAME} sam.json -d 2:plan -s\" ), ( True , \" {NAME} sam.json -d 2:plan -s50\" ), ( True , \" {NAME} sam.json -d 2:3 -s50\" ), ( True , \" {NAME} sam.json -d 5:2,3:2,2:2 -s100 --axes 2 sam.json\" ) ] Main script The following code is only executed when the file is invoked as a script. def render(sam_file, res_file = None , ** opts): if sam_file is None : raise RenderError( \"ERROR -- expected positional argument <sam-file>\" ) model = read_model(sam_file) if \"config\" in model: apply_config(model[ \"config\" ], opts) axes = opts[ \"orientation\" ] if opts[ \"plotter\" ] == \"gnu\" : GnuPlotter(model, axes).plot_frames() sys.exit() #for obj in opts[\"show_objects\"]: # plt[obj] ax = plot_skeletal(model,axes = axes) if res_file is not None : from urllib.parse import urlparse res_path = urlparse(res_file) with open (res_path[ 2 ], \"r\" ) as f: res = yaml.load(f,Loader = yaml.Loader) if res_path[ 4 ]: # query parameters passed res = res[ int (res_path[ 4 ].split( \"=\" )[ - 1 ])] else : res = {} for n,d in opts[ \"displ\" ]: v = res.setdefault(n,[ 0.0 ] * model[ \"nodes\" ][n][ \"ndf\" ]) if d < 3 : # translational dof v[d] += 1.0 else : v[d] += 0.1 # apply scale scale = opts[ \"scale\" ] if scale != 1.0 : for n in res.values(): for i in range ( len (n)): n[i] *= scale ax = plot_nodes(model, res, ax = ax, axes = axes) if res: plot_displ(model, res, axes = axes, ax = ax) # Handle plot formatting set_axis_limits(ax) ax.view_init( ** VIEWS[opts[ \"view\" ]]) if \"origin\" in opts[ \"show_objects\" ]: add_origin(ax, scale) if opts[ \"write_file\" ]: # write plot to file if file name provided if \"html\" in opts[ \"write_file\" ]: fig = plot_plotly(model,axes,displ = res,opts = opts) import plotly print ( str ( id (model)), file = sys.stderr) html = plotly.io.to_html(fig, div_id = str ( id (model)), ** opts[ \"save_options\" ][ \"html\" ]) with open (opts[ \"write_file\" ], \"w+\" ) as f: f.write(html) else : ax.figure.savefig(opts[ \"write_file\" ]) else : # otherwise show in new window import matplotlib.pyplot as plt plt.show() return ax if __name__ == \"__main__\" : opts = parse_args(sys.argv) try : render( ** opts) except ( FileNotFoundError ,RenderError) as e: print (e, file = sys.stderr) print ( f\" Run ' { NAME } --help' for more information\" , file = sys.stderr) sys.exit()","title":"OpenSees Rendering\n"},{"location":"tools/aleatoire/","text":"Aleatoire A set of tools for the probabilistic analysis of systems. Table of contents Installation A rough compilation of general-purpose system reliability functions and classes written over the course of a semester. This package implements probability transformations composed of marginal distributions which are defined using objects from the popular scipy.stats statistical library. This package is largely built upon the framework for reliability computations layed out in CalRel and FERUM. Installation pip install aleatoire You can also install the in-development version with: pip install https://github.com/claudioperez/aleatoire/archive/master.zip","title":"Aleatoire"},{"location":"tools/pyg3/","text":"PyG3 PyG3 is a Python library which exposes a high-level interface to OpenSees Documentation is under development","title":"PyG3\n"},{"location":"tools/quakeio/","text":"quake-io ![](https://github.com/claudioperez/quakeio/actions/workflows/base.yaml/badge.svg) [![PyPI Downloads][pypi-v-image]][pypi-v-link] [![PyPI Version][pypi-d-image]][pypi-d-link] ![][cov-img] [![Commits since latest release][gh-image]][gh-link] QuakeIO is a library of utilities for parsing and processing ground motion files. All data is serialized into a standardized JSON representation with a strictly defined schema . Interfaces are provided for Python, Matlab, and the command line. The following table summarizes the file formats which are currently supported: Format Read Write Reference Data Type [quakeio.]json \u2611 \u2611 schema any csmip.v2 \u2611 \u2610 CSMIP C/S csmip.zip \u2611 \u2610 E/R/C/S eqsig \u2611 \u2611 eqsig opensees \u2610 \u2611 PEER.NGA \u2611 \u2610 Design Ground motion data is represented by compositions of the following data types/containers: QuakeSeries is an array-like data type which contains a single time series, and associated metadata like peak values and units. All data contained by this type is generally closely related to a single physical quantity or measurement . An example of a file format which parses to this type is the PEER NGA .AT2 file. QuakeComponent is a collection of QuakeSeries types which generally represents time series data (e.g. acceleration, velocity, displacement) which were collected in a single direction . An example of a file format that parses into this type is the CSMIP Volume 2 ( .V2 ) spec. QuakeMotion is a collection of QuakeComponent types which all pertain to a single shared spatial location . The data contained by this type is generally free of any spatial variation. QuakeCollection is a collection of QuakeMotion types, often corresponding to a single site . An example of a file format that parses into this type is the CSMIP processed archive ( .zip ). The core functionality of the library is exposed by the quakeio.read(filename, format = None ) function. This function will return an object either of type (1), (2) or (3), depending on the format of the file that was parsed. For example, the return value of read when parsing a PEER NGA file (file extension .AT2 ), is a QuakeSeries with acceleration data. When parsing a CSMIP Volume 2 file the return is a QuakeComponent containing QuakeSeries instances for acceleration, velocity and displacement values, and when parsing a zip archive of such files, a QuakeCollection is returned. When used via the Python library, these types are overloaded with mathematical operations allowing for concise and expressive post-processing. For example, given two QuakeMotion objects top and bot , representing the motion at the top and bottom of a bridge column, respectively, their relative motion is simply computed as follows: >>> top - bot QuakeMotion( \"Hayward\" ) The resulting QuakeMotion has acceleration, velocity and displacement components all equal to the respective difference between those of top and bot . These operations are further developed in Example:Hayward Tooling and Standards Verification, Validation, and Continuous Integration The tests/ directory of the source code tree contains a suite of integration tests. An automated continuous integration workflow ensures that these tests are executed everytime that a change to the source code is pushed back to the upstream repository. Command Line Interface usage: quakeio [MODE] [OPTIONS] [FILE] Options: -f/--from FORMAT -t/--to FORMAT MATLAB Interface The Matlab interface utilizes the standard jsondecode function internally to read a JSON file and build a struct with fields corresponding to the Quake schemas. Motion = quakeIO . read ( 'csmip.zip' )","title":"quake-io\n"},{"location":"tools/quakeio/examples/","text":"Examples for the QuakeIO Library Seismic event analysis (Meloland Overpass) Limit state evaluation (Hayward Interchange) System Identification (Painter Street Overpass) San Bernardino","title":"Examples for the `QuakeIO` Library\n"},{"location":"tools/quakeio/examples/basic/","text":"Basic Operations Basics Python import quakeio csmip_event = quakeio.read( \"dat/58658_007_20210426_10.09.54.P.zip\" ) record = csmip_event[ \"bent_4_north_column_grnd_level\" ] component = record[ \"long\" ] series = component.accel series.plot() # #csmip_event[\"chan001\"].plot() # #csmip_event[\"chan001\"].plot_spect()","title":"Basic Operations\n"},{"location":"tools/quakeio/examples/bernardino/","text":"San Bernardino import quakeio import quakeio.processing as proc c = quakeio.read( \"../dat/BigBear92_ce23631p.zip\" , exclusions = [ \"filter*\" ]) proc.Spectrum(c.motions[ \"north_abutment\" ]. long , damping = [ 0.001 , 0.01 ]).plot() ;","title":"San Bernardino\n"},{"location":"tools/quakeio/examples/embedded-svg/","text":"Embedded SVG Output # [----------OPTIONS---------] [-FILE-] quakeio -tsvg --embed-in layout.svg data.zip # [----------OPTIONS---------] [-FILE-] quakeio -tsvg --embed-in layout.svg data.zip --plot su,psa,psv","title":"Embedded SVG Output\n"},{"location":"tools/quakeio/examples/hayward/","text":"Drift Demands (Hayward) This example uses the quakeio package to parse a collection of ground motion records and calculate drift demands. import quakeio import quakeio.processing as spec # file_name = \"../dat/58658_007_20210426_10.09.54.P.zip\" file_name = \"../dat/nc73654060_ce58658p.zip\" collection = quakeio.read(file_name, \"csmip.zip\" ) # collection.motions.keys() top = collection.at(key = \"bent_4_north_column_top\" ) bot = collection.at(key = \"bent_4_north_column_grnd_level\" ) spec.plot_grid(series = [top.tran.displ, bot.tran.displ], label = [ \"Structure\" , \"Ground\" ]) inches_to_cm = 2.54 height = 47.0 * 12.0 * inches_to_cm relative_resp = (top - bot). slice ( 28. , 60. ) # relative_resp is a QuakeMotion with long,tran,vert series ax = relative_resp. long .displ.plot() ax = relative_resp.tran.displ.plot(ax = ax) ax = relative_resp.resultant().displ.plot(ax = ax) resultant_drift = relative_resp.resultant().displ[ \"peak_value\" ] / height transverse_drift = relative_resp.tran.displ[ \"peak_value\" ] / height 5.7846756828653446e-05 -5.362784106773887e-05 for component in collection.components: spec.Spectrum(component, damping = [ 0.001 , 0.01 ]).plot() spec.TransferFunction((top. long ,bot. long ), damping = [ 0.001 , 0.01 , 0.05 ]).plot() ; spec.Spectrum(bot. long , damping = [ 0.0 , 0.01 ]).plot() <AxesSubplot:title={'center':'Response spectrum (Chn. 12)'}, xlabel='Period, (sec.)'>","title":"Drift Demands (Hayward)\n"},{"location":"tools/quakeio/examples/meloland/","text":"Event analysis (Meloland) This notebook uses the quakeio Python package to parse and process a suite of ground motion files. Meloland Overpass schematic placement of sensors import numpy as np import quakeio import quakeio.processing as spec The following file contains a collection of ground motions in the CSMIP Volume 2 format from the 1979 Imperial Valley earthquake (obtained from www.strongmotioncenter.org). file_name = \"../dat/imperialvalley79_ce01336p.zip\" The signature of the function quakeio.read is as follows: def read(filename: str , format : str = None , ** parser_options): ... where format is a string indicating the file format (see tool documentation for available formats ). In this case the format argument can be ommited because the CSMIP archive parser is the default parser for files with a .zip extension. collection = quakeio.read(file_name, exclusions = [ \"filter*\" ]) The variable collection now holds a QuakeCollection . Once the collection has been parsed, individual components can be extracted using the .at method of QuakeCollection component = collection.at(file_name = \"chan02.v2\" .upper()) Acceleration Spectra spec.Spectrum(component, damping = [ 0.0 , 0.01 , 0.05 ]).plot() ;","title":"Event analysis (Meloland)\n"},{"location":"tools/quakeio/examples/system_id-painter/","text":"System Identification (Painter Street Overpass) Painter Street Overpass (Rio Dell Hwy) import numpy as np import quakeio import quakeio.processing as spec # file_name = \"../dat/tomsplace_26nov2006_ce54730p.zip\" file_name = \"../dat/RioDell_Petrolia_Processed_Data.zip\" collection = quakeio.read(file_name, \"csmip.zip\" ) System Identification Case 1 : Input in transverse direction, output in transverse direction Input channels: 3; Output channels: 7 Case 2 : Input in longitudinal direction, output in longitudinal direction Input channels: 1; Output channel: 11 Case 3 : Input in longitudinal direction, output in vertical direction Considering that the bridge is similar to a frame in the longitudinal direction, shaking along this direction results in long. translational accelerations as well as bending & rotation of the deck, causing vertical accelerations on deck nodes. Case 3 makes use of this behavior to identify the long. mode. The influence vector of long. ground motions on vertical accelerations is zero, which is a concern, but this is still a useful case. Input channels: 1; Output channels: 6 Case 4 : Input in longitudinal direction, output in longitudinal & vertical directions. This is a case that can only be applied to OKID-ERA-DC. Therefore, it is the same as Case 3 in TFE, and similar to Case 3 in OKID-ERA-DC, except that the output channels is a combination of longitudinal & vertical channels. Input channels: 1; Output channels: 6 Case 5 : Input in vertical direction, output in vertical direction Input channels: 2; Output channel: 6 cases = { \"1\" : ( \"3\" , \"7\" ), \"2\" : ( \"2\" , \"11\" ), \"3\" : ( \"1\" , \"6\" ), \"4\" : ( \"2\" , \"6\" ) } The TransferFunction class is used to compute the transfer function between two channels at a specified damping ratio. for pair in cases.values(): inp = collection.at(channel = pair[ 0 ]) out = collection.at(channel = pair[ 1 ]) tf = spec.TransferFunction((inp,out), damping = [ 0.001 , 0.01 ]).plot() for component in collection.components: spec.Spectrum(component, damping = [ 0.0 , 0.01 ]).plot() spec.Spectrum(bot. long , damping = [ 0.0 , 0.01 ]).spect(bot. long ).shape --------------------------------------------------------------------------- NameError Traceback (most recent call last) /tmp/ipykernel_2714/326875978.py in <module> ----> 1 spec.Spectrum(bot.long, damping=[0.0, 0.01]).spect(bot.long).shape NameError: name 'bot' is not defined motion. long .veloc.data[ - 1 ] component.keys()","title":"System Identification (Painter Street Overpass)\n"}]}